---
phase: 02-error-handling
plan: 03
type: execute
---

<objective>
Ensure graceful degradation and comprehensive error logging for production resilience.

Purpose: Keep the daemon running through transient failures with clear diagnostic logging
Output: Robust watch mode that continues operating despite provider failures, with actionable error messages
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-phase.md
~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

**Prior plan context:**
- 02-01: Fixed JSON parsing vulnerabilities
- 02-02: Added retry logic with exponential backoff

**Current behavior:**
- Watch mode continues running after sync errors (good)
- Some error messages lack context for debugging
- Provider factory functions have unclear error messages on typos

**Relevant source:**
@src/external_dns/cli.py
- main() watch loop (1162-1225)
- Provider factories (641-666)
- sync_once error handling (934-943)

**From CONCERNS.md:**
- Provider factory functions: "Typo in DNS_PROVIDER env var causes unclear error"
</context>

<tasks>

<task type="auto">
  <name>Task 1: Improve error context and logging</name>
  <files>src/external_dns/cli.py, tests/test_utils.py</files>
  <action>
  Improve error messages throughout the codebase for better debugging in production.

  **1. Improve provider factory error messages (lines 641-666):**

  ```python
  def create_dns_provider() -> DNSProvider:
      """Factory function to create the configured DNS provider."""
      supported = ["adguard"]
      if DNS_PROVIDER == "adguard":
          return AdGuardDNSProvider(ADGUARD_URL, ADGUARD_USERNAME, ADGUARD_PASSWORD)
      else:
          raise ValueError(
              f"Unsupported DNS_PROVIDER: '{DNS_PROVIDER}'. "
              f"Supported providers: {', '.join(supported)}. "
              f"Check your DNS_PROVIDER environment variable."
          )

  def create_proxy_provider() -> ReverseProxyProvider:
      """Factory function to create the configured reverse proxy provider."""
      supported = ["traefik"]
      if PROXY_PROVIDER == "traefik":
          return TraefikProxyProvider(...)
      else:
          raise ValueError(
              f"Unsupported PROXY_PROVIDER: '{PROXY_PROVIDER}'. "
              f"Supported providers: {', '.join(supported)}. "
              f"Check your PROXY_PROVIDER environment variable."
          )
  ```

  **2. Add error context to provider failures:**

  In AdGuard `test_connection()`, `get_records()`, `add_record()`, `delete_record()`:
  - Include URL (without credentials) in error messages
  - Include HTTP status code when available

  ```python
  except requests.exceptions.RequestException as e:
      status_info = ""
      if hasattr(e, 'response') and e.response is not None:
          status_info = f" (HTTP {e.response.status_code})"
      logger.error(f"Failed to connect to {self.name} at {self._url}{status_info}: {e}")
      return False
  ```

  **3. Add error context in sync_once for instance failures (line 934-943):**

  ```python
  except requests.exceptions.RequestException as e:
      instance_success[instance.name] = False
      instance_seen_domains[instance.name] = set()
      error_detail = str(e)
      if hasattr(e, 'response') and e.response is not None:
          error_detail = f"HTTP {e.response.status_code}: {e}"
      prev = state["instances"].get(instance.name, {})
      state["instances"][instance.name] = {
          "last_success": prev.get("last_success", 0),
          "last_error": error_detail,
          "url": instance.url,
      }
      logger.warning(f"Proxy instance '{instance.name}' ({instance.url}) unreachable: {error_detail}")
  ```

  **4. Add startup diagnostic logging in main():**

  After provider creation, log diagnostic info:
  ```python
  logger.info(f"DNS Provider: {dns_provider.name} ({ADGUARD_URL})")
  logger.info(f"Proxy Provider: {proxy_provider.name}")
  for inst in instances:
      logger.info(f"  - {inst.name}: {inst.url} -> {inst.target_ip}")
  ```

  **Add tests:**
  - `test_create_dns_provider_error_message_includes_suggestions` - verify error message is actionable
  - `test_create_proxy_provider_error_message_includes_suggestions`
  </action>
  <verify>
  - `make lint` passes
  - `make test` passes all tests including new ones
  - Error messages include URL context and actionable suggestions
  </verify>
  <done>
  - Provider factory errors include supported provider list and env var hint
  - HTTP errors include status codes when available
  - Instance failures logged with URL context
  - At least 2 new tests for error message quality
  </done>
</task>

<task type="auto">
  <name>Task 2: Ensure continuous operation in watch mode</name>
  <files>src/external_dns/cli.py, tests/test_syncer.py</files>
  <action>
  Verify and strengthen watch mode resilience to ensure the daemon never crashes from recoverable errors.

  **1. Add catch-all in watch loop (around line 1167-1225):**

  Ensure the watch loop catches ALL exceptions in sync_once and continues:
  ```python
  while True:
      try:
          syncer.sync_once()
      except Exception as e:
          logger.error(f"Sync cycle failed: {e}", exc_info=True)
          # Continue to next cycle - don't crash the daemon
          # State is preserved from last successful sync
  ```

  **2. Handle DNS provider connection loss gracefully:**

  In sync_once(), if DNS provider operations fail, log and continue:
  - get_records() already returns [] on error (good)
  - add_record/delete_record already return False on error (good)
  - Verify these don't raise uncaught exceptions

  **3. Add periodic health check logging in watch mode:**

  Add a simple health indicator every N cycles:
  ```python
  cycle_count = 0
  while True:
      cycle_count += 1
      try:
          syncer.sync_once()
          if cycle_count % 10 == 0:  # Every 10 cycles
              logger.info(f"Health check: {cycle_count} sync cycles completed")
      except Exception as e:
          logger.error(f"Sync cycle {cycle_count} failed: {e}", exc_info=True)
  ```

  **4. Test graceful degradation:**

  Add tests in test_syncer.py:
  - `test_sync_continues_when_dns_provider_unavailable` - DNS provider returns errors, sync logs and continues
  - `test_sync_handles_all_instances_failing` - all proxy instances fail, state preserved, no crash
  - `test_sync_recovers_after_transient_failure` - fail then succeed on next call

  These tests should verify:
  - No uncaught exceptions propagate
  - State file is not corrupted
  - Next sync cycle can proceed normally
  </action>
  <verify>
  - `make lint` passes
  - `make test` passes all tests including new ones
  - Watch loop has exception handling around sync_once
  - Periodic health logging added
  </verify>
  <done>
  - Watch loop catches all exceptions and continues
  - Health check logging every 10 cycles
  - At least 3 new tests for degradation scenarios
  - Phase 2 complete
  </done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] `make lint` passes (ruff check)
- [ ] `make test` passes all tests
- [ ] Error messages are actionable and include context
- [ ] Watch mode continues operating through failures
- [ ] Health check logging provides visibility into daemon status
</verification>

<success_criteria>
- All tasks completed
- All verification checks pass
- Error messages include URLs, status codes, and suggestions
- Watch mode never crashes from provider failures
- At least 5 new tests for error handling scenarios
- Phase 2: Error Handling Hardening complete
</success_criteria>

<output>
After completion, create `.planning/phases/02-error-handling/02-03-SUMMARY.md`

**Phase completion checklist:**
- [ ] Update .planning/ROADMAP.md to mark Phase 2 complete
- [ ] Update .planning/STATE.md with Phase 2 completion
</output>
