---
phase: 01-testing-foundation
plan: 03
type: execute
---

<objective>
Enhanced integration tests and edge case coverage.

Purpose: Strengthen the existing Docker-based integration test with additional scenarios, and add utility function tests to complete Phase 1 testing coverage.

Output: Enhanced `tests/integration/test_docker_stack.py` and expanded `tests/test_utils.py`
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-phase.md
~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/codebase/TESTING.md

**Prior plan summaries:**
@.planning/phases/01-testing-foundation/01-01-SUMMARY.md
@.planning/phases/01-testing-foundation/01-02-SUMMARY.md

**Codebase constraints:**
- Integration tests require `EXTERNAL_DNS_RUN_DOCKER_TESTS=1` env var
- Integration tests use `@pytest.mark.integration` marker
- Docker stack in `docker-compose.integration.yaml`

**Key source files:**
@tests/integration/test_docker_stack.py (existing integration test)
@tests/test_utils.py (existing utility tests)
@src/external_dns/cli.py (utility functions around lines 121-156, 673-745)
</context>

<tasks>

<task type="auto">
  <name>Task 1: Expand utility function tests</name>
  <files>tests/test_utils.py</files>
  <action>
Expand `tests/test_utils.py` to cover more utility functions:

**Static rewrite parsing (expand existing):**
- `test_parse_static_rewrites_multiple_entries`: Comma-separated list → all parsed
- `test_parse_static_rewrites_whitespace_handling`: Extra spaces → trimmed correctly
- `test_parse_static_rewrites_invalid_format_returns_empty`: Malformed input → returns empty dict (graceful)

**Exclude pattern parsing (expand existing):**
- `test_parse_exclude_patterns_empty_string`: Empty input → empty list
- `test_parse_exclude_patterns_single_exact`: Single domain → one pattern
- `test_parse_exclude_patterns_invalid_regex_skipped`: Invalid regex → skipped with warning (if applicable)

**Domain exclusion (expand existing):**
- `test_is_domain_excluded_case_sensitive`: Exact match is case-sensitive
- `test_is_domain_excluded_empty_patterns`: No patterns → nothing excluded

**Boolean parsing (_parse_bool):**
- `test_parse_bool_true_values`: "true", "1", "yes", True → True
- `test_parse_bool_false_values`: "false", "0", "no", False → False
- `test_parse_bool_default_on_invalid`: Invalid input → uses default

**Config file finding:**
- `test_find_config_files_single_file_path`: Single file path → returns that file
- `test_find_config_files_directory_finds_yaml_and_json`: Dir with .yaml and .json → both found
- `test_find_config_files_empty_directory`: Empty dir → empty list
- `test_find_config_files_nonexistent_path`: Bad path → empty list

Import additional functions from cli.py as needed. Follow existing test patterns.
  </action>
  <verify>pytest tests/test_utils.py -v passes all tests</verify>
  <done>Utility function tests expanded with ~15 additional tests</done>
</task>

<task type="auto">
  <name>Task 2: Document integration test scenarios and add test helpers</name>
  <files>tests/integration/test_docker_stack.py</files>
  <action>
Review and enhance the existing integration test file:

1. **Add docstrings** explaining what each test verifies and its prerequisites

2. **Add test helper functions** (if not already present):
   - `_get_adguard_rewrites()`: Fetch current DNS rewrites from AdGuard API
   - `_create_traefik_route(hostname, router_name)`: Helper to create test routes dynamically (if possible via labels/config)
   - `_assert_rewrite_exists(domain, answer)`: Assert DNS rewrite exists
   - `_assert_rewrite_not_exists(domain)`: Assert DNS rewrite does not exist

3. **Add scenario documentation** as comments or docstrings:
   - What the test stack contains (Traefik, AdGuard, external-dns containers)
   - How routes are configured (Docker labels on test containers)
   - Expected sync behavior

4. **Verify test covers core scenarios:**
   - Route added → DNS record appears
   - Route removed → DNS record deleted (if this is testable in current setup)
   - Sync is idempotent (running twice produces same result)

If modifying tests is risky (they're slow/complex), focus on documentation and helper functions. Don't break working tests.

Note: Integration tests are slow and require Docker. The goal is to make them more maintainable and documented, not necessarily to add many new scenarios (unit tests cover most logic).
  </action>
  <verify>EXTERNAL_DNS_RUN_DOCKER_TESTS=1 pytest tests/integration/ -v --tb=short passes (if Docker available)</verify>
  <done>Integration test file has clear documentation and helper functions for maintainability</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] `make lint` passes (ruff check)
- [ ] `make test` passes all unit tests
- [ ] Integration tests documented (even if not all run locally)
- [ ] No regressions in existing tests
</verification>

<success_criteria>
- tests/test_utils.py expanded with additional utility tests
- tests/integration/test_docker_stack.py has clear documentation
- All unit tests pass
- No ruff linting errors
- Phase 1 complete: comprehensive test coverage for sync logic and providers
</success_criteria>

<output>
After completion, create `.planning/phases/01-testing-foundation/01-03-SUMMARY.md`

This is the final plan for Phase 1. After completing this plan:
- Update ROADMAP.md to mark Phase 1 complete
- Update STATE.md with phase completion and metrics
</output>
